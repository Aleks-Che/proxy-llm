
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional, Union
import time
import logging
import asyncio
from providers.deepseek import DeepSeekProvider
from providers.moonshot import MoonshotProvider
from providers.local import LocalProvider
from utils.token_counter import TokenCounter
from config import Config

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

# Middleware –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
@app.middleware("http")
async def log_requests(request, call_next):
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    logger.info(f"üîç Request from {client_ip}: {request.method} {request.url}")
    logger.info(f"üîç Headers: {dict(request.headers)}")
    
    # –¢–æ–ª—å–∫–æ –ª–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–ª–µ, –Ω–æ –Ω–µ —á–∏—Ç–∞–µ–º –µ–≥–æ
    if request.method == "POST":
        content_length = request.headers.get("content-length", "unknown")
        logger.info(f"üîç Content-Length: {content_length}")

    try:
        response = await call_next(request)
        logger.info(f"‚úÖ Response: {response.status_code}")
        logger.info(f"‚úÖ Response headers: {dict(response.headers)}")
        return response
    except Exception as e:
        logger.error(f"‚ùå Error in request processing: {e}")
        raise

# –î–æ–±–∞–≤–ª—è–µ–º CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã
providers = {}
if Config.DEEPSEEK_API_KEY and Config.DEEPSEEK_API_KEY != "sk-–≤–∞—à-–∫–ª—é—á-–∑–¥–µ—Å—å":
    providers["deepseek"] = DeepSeekProvider()
    logger.info("DeepSeek provider initialized")
if Config.MOONSHOT_API_KEY:
    providers["moonshot"] = MoonshotProvider()
    logger.info("Moonshot provider initialized")

# –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
providers["local"] = LocalProvider()
logger.info("Local provider initialized")

current_provider = Config.DEFAULT_PROVIDER if Config.DEFAULT_PROVIDER in providers else "local"
token_counter = TokenCounter()

class ChatMessage(BaseModel):
    role: str
    content: Union[str, List[Dict[str, Any]], Dict[str, Any]]  # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ content
    
    class Config:
        extra = "allow"  # –†–∞–∑—Ä–µ—à–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è

class ChatCompletionRequest(BaseModel):
    model: Optional[str] = None
    messages: Optional[List[ChatMessage]] = None
    temperature: Optional[float] = 1.0
    max_tokens: Optional[int] = None
    stream: Optional[bool] = False
    reasoning_effort: Optional[str] = None
    stream_options: Optional[Dict[str, Any]] = None
    top_p: Optional[float] = None
    presence_penalty: Optional[float] = None
    frequency_penalty: Optional[float] = None
    logit_bias: Optional[Dict[str, float]] = None
    user: Optional[str] = None
    suffix: Optional[str] = None
    echo: Optional[bool] = None
    best_of: Optional[int] = None
    logprobs: Optional[int] = None
    n: Optional[int] = None
    stop: Optional[List[str]] = None
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–æ–ª—è –æ—Ç Cline
    tools: Optional[List[Dict[str, Any]]] = None
    tool_choice: Optional[str] = None
    response_format: Optional[Dict[str, Any]] = None
    seed: Optional[int] = None
    max_completion_tokens: Optional[int] = None
    truncation_strategy: Optional[Dict[str, Any]] = None
    reasoning: Optional[Dict[str, Any]] = None
    parallel_tool_calls: Optional[bool] = None
    store: Optional[bool] = None
    metadata: Optional[Dict[str, Any]] = None
    
    # –†–∞–∑—Ä–µ—à–∞–µ–º –ª—é–±—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –æ—Ç Cline
    class Config:
        extra = "allow"

@app.get("/")
async def root():
    return {"message": "LLM Proxy Server running", "provider": current_provider}

@app.get("/health")
async def health():
    return {"status": "healthy", "provider": current_provider}

@app.get("/test")
async def test():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
    try:
        provider = providers[current_provider]
        messages = [{"role": "user", "content": "test"}]
        response = await provider.chat_completion(messages, max_tokens=5)
        return {"status": "ok", "response": response.choices[0].message.content}
    except Exception as e:
        return {"status": "error", "error": str(e)}

@app.post("/v1/chat/completions")
async def chat_completions(request: ChatCompletionRequest):
    logger.info("=== START PROCESSING ===")
    logger.info(f"Model requested: {request.model}")
    logger.info(f"Messages count: {len(request.messages) if request.messages else 0}")
    logger.info(f"Stream: {request.stream}")
    logger.info(f"Current provider: {current_provider}")
    
    try:
        provider = providers[current_provider]
        logger.info(f"Using provider: {current_provider}")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π - –±–æ–ª–µ–µ –≥–∏–±–∫–∞—è
        messages = []
        if request.messages:
            logger.info(f"Raw messages: {request.messages}")
            for i, msg in enumerate(request.messages):
                logger.info(f"Message {i}: role={msg.role}, content_type={type(msg.content)}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º content –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
                content = msg.content
                
                # –ï—Å–ª–∏ content - —Å—Ç—Ä–æ–∫–∞
                if isinstance(content, str):
                    processed_content = content
                # –ï—Å–ª–∏ content - —Å–ø–∏—Å–æ–∫ (–º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
                elif isinstance(content, list):
                    text_parts = []
                    for item in content:
                        if isinstance(item, dict):
                            if item.get("type") == "text":
                                text_parts.append(item.get("text", ""))
                            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º image_url –∏ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
                        elif isinstance(item, str):
                            text_parts.append(item)
                    processed_content = " ".join(text_parts)
                # –ï—Å–ª–∏ content - dict
                elif isinstance(content, dict):
                    processed_content = str(content)  # –ò–ª–∏ –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ dict
                # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤
                else:
                    processed_content = str(content)
                
                messages.append({
                    "role": msg.role,
                    "content": processed_content
                })
                
                logger.info(f"Processed message {i}: {processed_content[:100]}...")
        
        logger.info(f"Processed messages count: {len(messages)}")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
        kwargs = {"max_tokens": 1000}
        if request.max_tokens:
            kwargs["max_tokens"] = request.max_tokens
        if request.temperature is not None:
            kwargs["temperature"] = request.temperature
        if request.stream:
            kwargs["stream"] = True
            
        logger.info(f"Calling provider with {len(messages)} messages and kwargs: {kwargs}")
        
        # –í—ã–∑–æ–≤ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        response = await asyncio.wait_for(
            provider.chat_completion(messages, **kwargs),
            timeout=120.0  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
        )
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ streaming response
        if request.stream:
            logger.info("Streaming response requested")
            logger.info(f"Stream options: {request.stream_options}")
            logger.info(f"Reasoning effort: {request.reasoning_effort}")
            
            # –î–ª—è streaming –æ—Ç–≤–µ—Ç–æ–≤ —Å–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
            from fastapi.responses import StreamingResponse
            import json
            
            async def streaming_generator():
                # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è usage —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                input_tokens = token_counter.count_tokens(str(messages), current_provider)
                completion_tokens = 0
                accumulated_content = ""
                
                async for chunk in response:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —á–∞–Ω–∫–∞ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
                    content = ""
                    if hasattr(chunk, 'content'):
                        content = getattr(chunk, 'content', '')
                    elif hasattr(chunk, 'choices') and getattr(chunk, 'choices'):
                        choices = getattr(chunk, 'choices')
                        if choices and hasattr(choices[0], 'delta'):
                            delta = getattr(choices[0], 'delta')
                            if hasattr(delta, 'content'):
                                content = getattr(delta, 'content', '')
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º accumulated_content –∏ completion_tokens
                    if content:
                        accumulated_content += content
                        completion_tokens = token_counter.count_tokens(accumulated_content, current_provider)
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º chunk –≤ JSON-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
                    if hasattr(chunk, 'model_dump'):
                        chunk_dict = chunk.model_dump()
                    elif hasattr(chunk, 'to_dict'):
                        chunk_dict = chunk.to_dict()
                    elif hasattr(chunk, 'dict'):
                        chunk_dict = chunk.dict()
                    else:
                        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º Cline
                        chunk_dict = {
                            "id": f"chatcmpl-{int(time.time())}",
                            "object": "chat.completion.chunk",
                            "created": int(time.time()),
                            "model": request.model or current_provider,
                            "choices": [
                                {
                                    "index": 0,
                                    "delta": {
                                        "content": content,
                                        "reasoning_content": None  # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Cline
                                    },
                                    "finish_reason": getattr(chunk, 'finish_reason', None)
                                }
                            ]
                        }
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º completion_tokens –≤–æ –≤—Å–µ—Ö —á–∞–Ω–∫–∞—Ö
                    if request.stream_options and request.stream_options.get("include_usage", False):
                        chunk_dict["usage"] = {
                            "prompt_tokens": input_tokens,
                            "completion_tokens": completion_tokens,
                            "total_tokens": input_tokens + completion_tokens,
                            "prompt_tokens_details": {
                                "cached_tokens": 0  # –ü–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
                            },
                            "prompt_cache_miss_tokens": input_tokens
                        }
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ JSON –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω
                    try:
                        json_str = json.dumps(chunk_dict, ensure_ascii=False)
                        yield f"data: {json_str}\n\n"
                    except Exception as e:
                        logger.error(f"JSON serialization error: {e}")
                        yield f"data: {{\"error\": \"JSON serialization failed\"}}\n\n"
                
                # –§–∏–Ω–∞–ª—å–Ω—ã–π chunk —Å –ø–æ–ª–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π usage
                if request.stream_options and request.stream_options.get("include_usage", False):
                    final_chunk = {
                        "id": f"chatcmpl-{int(time.time())}",
                        "object": "chat.completion.chunk",
                        "created": int(time.time()),
                        "model": request.model or current_provider,
                        "choices": [
                            {
                                "index": 0,
                                "delta": {},
                                "finish_reason": "stop"
                            }
                        ],
                        "usage": {
                            "prompt_tokens": input_tokens,
                            "completion_tokens": completion_tokens,
                            "total_tokens": input_tokens + completion_tokens,
                            "prompt_tokens_details": {
                                "cached_tokens": 0
                            },
                            "prompt_cache_miss_tokens": input_tokens
                        }
                    }
                    try:
                        json_str = json.dumps(final_chunk, ensure_ascii=False)
                        yield f"data: {json_str}\n\n"
                    except Exception as e:
                        logger.error(f"Final chunk JSON error: {e}")
                
                yield "data: [DONE]\n\n"
            
            return StreamingResponse(
                streaming_generator(),
                media_type="text/event-stream"
            )
        
        logger.info("Response received successfully")
        output_text = response.choices[0].message.content
        
        # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤
        input_tokens = token_counter.count_tokens(str(messages), current_provider)
        output_tokens = token_counter.count_tokens(output_text, current_provider)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI API
        response_data = {
            "id": f"chatcmpl-{int(time.time())}",
            "object": "chat.completion",
            "created": int(time.time()),
            "model": request.model or current_provider,
            "choices": [{
                "index": 0,
                "message": {
                    "role": "assistant",
                    "content": output_text
                },
                "finish_reason": "stop"
            }],
            "usage": {
                "prompt_tokens": input_tokens,
                "completion_tokens": output_tokens,
                "total_tokens": input_tokens + output_tokens
            }
        }
        
        logger.info(f"Response formatted successfully. Tokens: {input_tokens}+{output_tokens}")
        return response_data
        
    except asyncio.TimeoutError:
        logger.error("Request timeout")
        raise HTTPException(status_code=504, detail="Request timeout")
    except Exception as e:
        logger.error(f"Error processing request: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ—É—Ç–µ—Ä –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é
from fastapi import APIRouter
v1_router = APIRouter(prefix="/v1")
app.include_router(v1_router)

# –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ endpoints –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
@app.get("/providers")
async def list_providers():
    """–°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
    return {"providers": list(providers.keys()), "current": current_provider}

@app.post("/switch-provider/{provider_name}")
async def switch_provider(provider_name: str):
    """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
    global current_provider
    if provider_name not in providers:
        raise HTTPException(status_code=400, detail=f"Provider {provider_name} not found")
    current_provider = provider_name
    return {"message": f"Switched to {provider_name}", "provider": current_provider}

@app.post("/debug/cline")
async def debug_cline_request(request: Request):
    """–≠–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—Ç Cline"""
    body = await request.body()
    body_str = body.decode('utf-8', errors='ignore')
    
    try:
        import json
        parsed = json.loads(body_str)
    except:
        parsed = {"error": "Invalid JSON"}
    
    return {
        "headers": dict(request.headers),
        "body": parsed,
        "raw_body": body_str,
        "method": request.method,
        "url": str(request.url)
    }

# –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ—Ç–ª–æ–≤–∞ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Pydantic
from fastapi import Request
from fastapi.responses import JSONResponse
from pydantic import ValidationError

@app.exception_handler(ValidationError)
async def validation_exception_handler(request: Request, exc: ValidationError):
    body = await request.body()
    body_str = body.decode('utf-8', errors='ignore') if body else "empty"
    
    logger.error("=== PYDANTIC VALIDATION ERROR ===")
    logger.error(f"Request body length: {len(body_str)}")
    logger.error(f"Request body preview: {body_str[:1000]}")
    logger.error(f"Validation errors: {exc.errors()}")
    
    # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    try:
        import json
        parsed = json.loads(body_str)
        logger.error(f"Parsed JSON keys: {list(parsed.keys())}")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º messages
        if 'messages' in parsed:
            messages = parsed['messages']
            logger.error(f"Messages count: {len(messages)}")
            if messages:
                first_msg = messages[0]
                logger.error(f"First message keys: {list(first_msg.keys())}")
                if 'content' in first_msg:
                    content = first_msg['content']
                    logger.error(f"Content type: {type(content)}")
                    if isinstance(content, str):
                        logger.error(f"Content preview: {content[:200]}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª—è
        known_fields = {
            'model', 'messages', 'temperature', 'max_tokens', 'stream',
            'reasoning_effort', 'stream_options', 'top_p', 'presence_penalty',
            'frequency_penalty', 'logit_bias', 'user', 'suffix', 'echo',
            'best_of', 'logprobs', 'n', 'stop', 'tools', 'tool_choice',
            'response_format', 'seed', 'max_completion_tokens', 'truncation_strategy',
            'reasoning', 'parallel_tool_calls', 'store', 'metadata'
        }
        unknown_fields = set(parsed.keys()) - known_fields
        if unknown_fields:
            logger.error(f"Unknown fields from Cline: {unknown_fields}")
            
    except Exception as e:
        logger.error(f"Error parsing request body: {e}")
    
    # –í–º–µ—Å—Ç–æ 422 –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 200 —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
    return JSONResponse(
        status_code=200,
        content={
            "error": "Validation failed - check logs",
            "cline_request": body_str[:500],
            "validation_errors": exc.errors()
        }
    )

# –î–æ–±–∞–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"‚ùå Global exception: {exc}")
    logger.error(f"‚ùå Exception type: {type(exc)}")
    import traceback
    logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
    return JSONResponse(
        status_code=500,
        content={"detail": str(exc), "type": str(type(exc))}
    )